# bruce_chat_app.py

import streamlit as st
from pathlib import Path
from huggingface_hub import InferenceClient

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Ø¨Ø±ÙˆØ³ ğŸ˜„", page_icon="ğŸ˜„", layout="centered")

# (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ø´Ø¹Ø§Ø±
logo_path = Path("assets/logo.png")
if logo_path.exists():
    st.image(str(logo_path), width=120)

st.title("Ø¨Ø±ÙˆØ³ ğŸ˜„")
st.caption("MVP â€” Ù…Ø­Ø§Ø¯Ø«Ø© Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø³ÙŠØ·Ø© (ØªØ¹Ù…Ù„ Ø¹Ø¨Ø± Hugging Face Inference)")

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„ØªÙˆÙƒÙ†
if "HF_TOKEN" not in st.secrets or not st.secrets["HF_TOKEN"]:
    st.error("ğŸ”‘ Ù…Ø§ Ù„Ù‚ÙŠØª HF_TOKEN ÙÙŠ Secrets. Ø±ÙˆØ­ Ù„Ù€ Manage app â†’ Settings â†’ Secrets ÙˆØ­Ø·Ù‡ Ù‡Ù†Ø§Ùƒ.")
    st.stop()

# Ø¹Ù…ÙŠÙ„ Hugging Face
MODEL_ID = "mistralai/Mistral-7B-Instruct-v0.3"  # Ù…ÙˆØ¯ÙŠÙ„ ÙŠØ¯Ø¹Ù… text-generation
client = InferenceClient(model=MODEL_ID, token=st.secrets["HF_TOKEN"])

# Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©
if "history" not in st.session_state:
    st.session_state.history = []  # [(user, assistant), ...]

SYSTEM_PROMPT = (
    "Ø£Ù†Øª Ø¨Ø±ÙˆØ³ØŒ Ø±Ø¯ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ ÙˆØ§Ø¶Ø­ ÙˆÙ„Ø·ÙŠÙØŒ ÙˆØ®Ù„Ù‘Ùƒ Ù…Ø®ØªØµØ± ÙˆÙ…ÙÙŠØ¯. "
    "Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù† Ø§Ù„ÙˆÙ‚Øª Ø£Ùˆ Ø´ÙŠØ¡ Ø¹Ø§Ù…ØŒ Ø¬Ø§ÙˆØ¨Ù‡ Ø¨Ø¨Ø³Ø§Ø·Ø©. "
    "ØªØ¬Ù†Ù‘Ø¨ Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ø·ÙˆÙŠÙ„ Ø¥Ù„Ø§ Ù„Ùˆ Ø·Ù„Ø¨ ØµØ±Ø§Ø­Ø©."
)

def build_prompt(history, user_message):
    """
    Ù†Ø¨Ù†ÙŠ prompt Ø¨Ø£Ø³Ù„ÙˆØ¨ [INST] Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ù…Ø«Ù„ Mistral-Instruct.
    """
    parts = [f"<s>[INST] {SYSTEM_PROMPT} [/INST]"]
    for u, a in history:
        parts.append(f"{a}</s><s>[INST] {u} [/INST]")
    parts.append("")  # ÙŠÙØµÙ„ Ø¢Ø®Ø± Ø±Ø¯
    parts.append(f"[/INST]")  # Ø¥ØºÙ„Ø§Ù‚ Ù„Ùˆ ÙÙŠ Ø³Ø·Ø± Ø³Ø§Ø¨Ù‚
    # Ø¢Ø®Ø± Ø±Ø³Ø§Ù„Ø© Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    prompt = "<s>[INST] " + user_message + " [/INST]"
    full = "\n".join(parts) + "\n" + prompt
    return full

def generate_response(history, user_message):
    prompt = build_prompt(history, user_message)
    # ØªÙˆÙ„ÙŠØ¯ Ù†Øµ
    out = client.text_generation(
        prompt,
        max_new_tokens=200,
        temperature=0.7,
        top_p=0.9,
        do_sample=True,
        repetition_penalty=1.1,
        stop=["</s>", "[INST]", "[/INST]"],  # ÙŠØ­Ø§ÙˆÙ„ ÙŠÙˆÙ‚Ù Ø¨Ø´ÙƒÙ„ Ù†Ø¸ÙŠÙ
        return_full_text=False,              # Ø±Ø¬Ù‘Ø¹ Ø§Ù„Ù†Ø§ØªØ¬ ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª
    )
    # `out` ÙŠÙƒÙˆÙ† Ø³ØªØ±Ù†Øº Ø§Ù„Ù†Ø§ØªØ¬
    return out.strip()

# ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø³ÙŠØ·Ø©
with st.form("chat"):
    user = st.text_input("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒâ€¦", "")
    sent = st.form_submit_button("Ø¥Ø±Ø³Ø§Ù„", use_container_width=True)

# Ø¹Ø±Ø¶ Ø§Ù„ØªØ§Ø±ÙŠØ®
for u, a in st.session_state.history:
    st.chat_message("user").markdown(u)
    st.chat_message("assistant").markdown(a)

if sent and user.strip():
    st.chat_message("user").markdown(user)
    with st.spinner("â³ Ø¨Ø±ÙˆØ³ ÙŠÙÙƒØ±â€¦"):
        try:
            reply = generate_response(st.session_state.history, user.strip())
        except Exception as e:
            st.error(f"ØµØ§Ø± Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø¯Ù…Ø©:\n\n{e}")
            st.stop()
    st.session_state.history.append((user.strip(), reply))
    st.chat_message("assistant").markdown(reply)

# Ø²Ø± Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
with st.sidebar:
    if st.button("Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.history = []
        st.success("Ø§Ù†Ù…Ø³Ø­Øª Ø§Ù„Ø³Ø§Ù„ÙØ© âœ…")
