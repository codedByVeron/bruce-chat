# bruce_chat_app.py
import streamlit as st
from huggingface_hub import InferenceClient
import os

# ===== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© =====
st.set_page_config(page_title="Ø¨Ø±ÙˆØ³ ğŸ˜", page_icon="ğŸ˜", layout="centered")
st.title("Ø¨Ø±ÙˆØ³ ğŸ˜")
st.caption("MVP â€” Ù…Ø­Ø§Ø¯Ø«Ø© Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø³ÙŠØ·Ø© ØªØ¹Ù…Ù„ Ø¹Ø¨Ø± Hugging Face Inference")

# ===== Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆÙƒÙ† =====
HF_TOKEN = os.getenv("HF_TOKEN")
if not HF_TOKEN:
    st.error("Ù…ÙÙ‚ÙˆØ¯ HF_TOKEN ÙÙŠ Secrets. Ø±ÙˆØ­ Ø¥Ù„Ù‰ Manage app â†’ Settings â†’ Secrets ÙˆØ­Ø·:\nHF_TOKEN = \"hf_...\"")
    st.stop()

# Ø§Ø®ØªØ± Ø£Ø­Ø¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ø¯Ø§Ø¹Ù…Ø© Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (chat)
MODEL_ID = st.sidebar.selectbox(
    "Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ:",
    [
        "HuggingFaceH4/zephyr-7b-beta",
        "mistralai/Mistral-7B-Instruct-v0.2",
        "tiiuae/falcon-7b-instruct",  # Ù„Ùˆ Ù…Ø§ Ø§Ø´ØªØºÙ„ Ø§Ø±Ø¬Ø¹ Ù„ÙˆØ§Ø­Ø¯ Ù…Ù† ÙÙˆÙ‚
    ],
    index=0,
)

SYSTEM_PROMPT = (
    "Ø£Ù†Øª Ø±ÙˆØ¨ÙˆØª Ø¯Ø±Ø¯Ø´Ø© Ø§Ø³Ù…Ù‡ Ø¨Ø±ÙˆØ³. Ø±Ø¯ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ ÙˆØ¯ÙˆØ¯ØŒ ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø®ØªØµØ±. "
    "Ø§Ø³ØªØ®Ø¯Ù… Ø¬Ù…Ù„ Ù‚ØµÙŠØ±Ø©ØŒ ÙˆØ§Ø°Ø§ Ù…Ø§ ØªÙ‚Ø¯Ø± ØªØ³Ø§Ø¹Ø¯ØŒ Ù‚Ù„ Ø°Ù„Ùƒ Ø¨ØµØ±Ø§Ø­Ø©."
)

# ===== ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ =====
client = InferenceClient(api_key=HF_TOKEN)

# ===== Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (ØµÙŠØºØ© Ù…Ø­Ø§Ø¯Ø«Ø©) =====
def generate_reply(history: list[tuple[str, str]], user_msg: str) -> str:
    """
    history: Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† tuples [(role, content), ...] Ù…Ø«Ù„:
             [("user","..."), ("assistant","..."), ...]
    """
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    # Ø£Ø¶Ù Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    for role, content in history:
        role = "assistant" if role == "assistant" else "user"
        messages.append({"role": role, "content": content})
    # Ø£Ø¶Ù Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠØ©
    messages.append({"role": "user", "content": user_msg})

    # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ chat.completions (Ù…Ùˆ text-generation)
    resp = client.chat.completions.create(
        model=MODEL_ID,
        messages=messages,
        max_tokens=350,
        temperature=0.7,
    )
    return resp.choices[0].message.content.strip()

# ===== ÙˆØ§Ø¬Ù‡Ø© Streamlit =====
if "history" not in st.session_state:
    st.session_state.history = []  # [(role, content)]

with st.form("chat_form", clear_on_submit=True):
    user_text = st.text_input("Ù…Ø«Ù„Ø§Ù‹: Ø£Ù‡Ù„Ù‹Ø§ Ø¨Ø±ÙˆØ³!", placeholder="Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ...", label_visibility="collapsed")
    submitted = st.form_submit_button("Ø¥Ø±Ø³Ø§Ù„")

if submitted and user_text.strip():
    with st.spinner("ÙŠÙƒØªØ¨â€¦"):
        try:
            reply = generate_reply(st.session_state.history, user_text.strip())
        except Exception as e:
            st.error(f"ØµØ§Ø± Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø¯Ù…Ø©:\n\n{e}\n\n"
                     "Ù„Ùˆ Ø´ÙØª Ø±Ø³Ø§Ù„Ø© 'not supported for task text-generation' ØªØ£ÙƒØ¯ Ø¥Ù†Ù†Ø§ Ù†Ø³ØªØ®Ø¯Ù… chat "
                     "ÙˆØ¬Ø±Ø¨ Ù…ÙˆØ¯ÙŠÙ„ Ø¢Ø®Ø± Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ.")
        else:
            st.session_state.history.append(("user", user_text.strip()))
            st.session_state.history.append(("assistant", reply))

# Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
for role, msg in st.session_state.history:
    if role == "user":
        st.chat_message("user").markdown(msg)
    else:
        st.chat_message("assistant").markdown(msg)

# Ø²Ø± Ù„Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
st.sidebar.subheader("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
if st.sidebar.button("Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
    st.session_state.history = []
    st.experimental_rerun()
